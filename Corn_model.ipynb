{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d82964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow \n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31436305",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\ASUS\\OneDrive - SRM Institute of Science & Technology\\Pictures\\whatsapp\\Green Bot\\Corn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab51241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4737 images belonging to 6 classes.\n",
      "Found 1181 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,          # Normalize pixel values to be between 0 and 1\n",
    "    shear_range=0.2,         # Shear intensity (for data augmentation)\n",
    "    zoom_range=0.2,          # Zoom range (for data augmentation)\n",
    "    horizontal_flip=True,    # Randomly flip images horizontally (for data augmentation)\n",
    "    validation_split=0.2      # Split the data into training and validation sets\n",
    ")\n",
    "\n",
    "# Create training data generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=(128, 128),   # Set your desired image size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Assuming you have categorical labels\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Create validation data generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13dedf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), strides=(2, 2), input_shape=(128, 128, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), strides=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), strides=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))  \n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Change the number of units in the output layer to 6 (number of classes)\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93c3de7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "148/148 [==============================] - 91s 616ms/step - loss: 0.3562 - accuracy: 0.8604 - val_loss: 0.4004 - val_accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 71s 480ms/step - loss: 0.3536 - accuracy: 0.8542 - val_loss: 0.4183 - val_accuracy: 0.8273\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 71s 480ms/step - loss: 0.3686 - accuracy: 0.8567 - val_loss: 0.4297 - val_accuracy: 0.8359\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 71s 479ms/step - loss: 0.3369 - accuracy: 0.8676 - val_loss: 0.3753 - val_accuracy: 0.8524\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 73s 495ms/step - loss: 0.3328 - accuracy: 0.8678 - val_loss: 0.4123 - val_accuracy: 0.8524\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 83s 563ms/step - loss: 0.3276 - accuracy: 0.8712 - val_loss: 0.3964 - val_accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 85s 577ms/step - loss: 0.4112 - accuracy: 0.8363 - val_loss: 0.3509 - val_accuracy: 0.8715\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 90s 607ms/step - loss: 0.3263 - accuracy: 0.8710 - val_loss: 0.3292 - val_accuracy: 0.8681\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 115s 777ms/step - loss: 0.2967 - accuracy: 0.8842 - val_loss: 0.3576 - val_accuracy: 0.8585\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 123s 828ms/step - loss: 0.3171 - accuracy: 0.8763 - val_loss: 0.3935 - val_accuracy: 0.8481\n"
     ]
    }
   ],
   "source": [
    "# Set batch size and train the model\n",
    "batch_size = 32\n",
    "\n",
    "# Assuming you have defined your data generators as 'train_generator' and 'validation_generator'\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Optionally, you can save the trained model\n",
    "model.save('plant_disease_detection_model.h5')\n"
   ]
  },
   {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65t346r6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "The detected disease is: common_rust\n"
     ]
    }
   ],
   "source": [
    "img_path = r\"C:\\Users\\ASUS\\Downloads\\corn input 2.jpeg\"\n",
    "img = image.load_img(img_path, target_size=(128, 128))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0 \n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "class_indices = train_generator.class_indices\n",
    "predicted_class = list(class_indices.keys())[np.argmax(prediction)]\n",
    "print(f'The detected disease is: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24cd6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\ASUS\\Coding Ninjas\\model\\corn api.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

